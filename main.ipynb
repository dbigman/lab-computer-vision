{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaLHjbgl4sdC"
   },
   "source": [
    "# Computer Vision (Image operators and filters)\n",
    "\n",
    "By the end of this lab, you will get hands on experience working with:\n",
    "\n",
    "*   Image Handling\n",
    "*   Image Manipulation\n",
    "*   Histogram and Histogram Equalization\n",
    "*   Basic filtering techniques\n",
    "\n",
    "<!-- ### **Remember this is a graded exercise.** -->\n",
    "\n",
    "**Reminder**:\n",
    "\n",
    "*   For every plot, make sure you provide appropriate titles, axis labels, legends, wherever applicable.\n",
    "*   Add sufficient comments and explanations wherever necessary.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BuqI1scQ4imT"
   },
   "outputs": [],
   "source": [
    "# Loading necessary libraries (Feel free to add new libraries if you need for any computation)\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import data, exposure, filters, io, morphology "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OV5XxAg85xJ_"
   },
   "source": [
    "# Channels and color spaces\n",
    "\n",
    "### **Exercise: Image Creation and Color Manipulation**\n",
    "\n",
    "*   Create a 100 x 100 image for each of the below visualization\n",
    "\n",
    "\n",
    "*   Visualize the created images in a 1 x 3 subplot using matplotlib.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvftuOlr5woU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the patterns\n",
    "patterns = [\n",
    "    np.block([[np.zeros((100, 50)), np.ones((100, 50))]]),  \n",
    "    np.block([[np.zeros((50, 100))], [np.ones((50, 100))]]),  \n",
    "    np.block([[np.ones((50, 50)), np.zeros((50, 50))], [np.zeros((50, 100))]])# Top-left corner\n",
    "]\n",
    "\n",
    "\n",
    "# Plot the corrected patterns\n",
    "fig, axes = plt.subplots(1, 3, figsize=(9, 3), facecolor='black')\n",
    "\n",
    "for ax, pattern in zip(axes, patterns):\n",
    "    ax.imshow(pattern, cmap='gray')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJ52BL-WrWV-"
   },
   "source": [
    "*   Use the above three images to create the following image\n",
    "\n",
    "\n",
    "*Hint: Remember channels and color spaces*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VjFNuJ4Rraiw"
   },
   "outputs": [],
   "source": [
    "# Create the new composite image from the previously defined patterns\n",
    "from PIL import Image\n",
    "\n",
    "# Define individual components as PIL images\n",
    "vertical_split = Image.fromarray((patterns[0] * 255).astype('uint8')).convert('L')\n",
    "horizontal_split = Image.fromarray((patterns[1] * 255).astype('uint8')).convert('L')\n",
    "top_left_corner = Image.fromarray((patterns[2] * 255).astype('uint8')).convert('L')\n",
    "\n",
    "# empty RGB image\n",
    "composite_image = Image.new(\"RGB\", (100, 100))\n",
    "\n",
    "# Define color mappings for each pattern\n",
    "blue = (0, 0, 255)       # Blue\n",
    "red = (255, 0, 0)        # Red\n",
    "green = (0, 255, 0)      # Green\n",
    "yellow = (255, 255, 0)   # Yellow\n",
    "\n",
    "# Assign colors based on patterns\n",
    "for x in range(100):\n",
    "    for y in range(100):\n",
    "        if vertical_split.getpixel((x, y)) == 255 and horizontal_split.getpixel((x, y)) == 0:\n",
    "            composite_image.putpixel((x, y), red) # Top-right \n",
    "        elif top_left_corner.getpixel((x, y)) == 255:\n",
    "            composite_image.putpixel((x, y), blue) # Top-left\n",
    "            \n",
    "            \n",
    "        elif vertical_split.getpixel((x, y)) == 255 and horizontal_split.getpixel((x, y)) == 255:\n",
    "             composite_image.putpixel((x, y), yellow)  # Bottom-right\n",
    "\n",
    "            \n",
    "        else:\n",
    "            # composite_image.putpixel((x, y), yellow)  # Bottom-right\n",
    "            composite_image.putpixel((x, y), green)\n",
    "\n",
    "# Display the final composite image\n",
    "composite_image.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3jnTbnqIkN_"
   },
   "source": [
    "### **Exercise: Color Manipulation**\n",
    "\n",
    "*   Read the image 'sillas.jpg' from the images folder\n",
    "\n",
    "\n",
    "*   Extract individual channels and plot them using matplotlib subplot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6T8NHYIAJ7fr"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# C:\\Users\\dbigman\\OneDrive - SUDOC LLC\\Desktop\\GitHub\\Ironhack_bootcamp\\lab-computer-vision\\images\\sillas.jpg\n",
    "# Load a sample JPG image\n",
    "sample_image_path = r\"images\\sillas.jpg\"\n",
    "\n",
    "image = Image.open(sample_image_path).convert('RGB')\n",
    "\n",
    "# Extract individual channels\n",
    "red_channel, green_channel, blue_channel = image.split()\n",
    "\n",
    "# Plot the channels\n",
    "fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "# Display the original image\n",
    "axes[0].imshow(image)\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# Display the Red channel\n",
    "axes[1].imshow(red_channel, cmap='Reds')\n",
    "axes[1].set_title(\"Red Channel\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "# Display the Green channel\n",
    "axes[2].imshow(green_channel, cmap='Greens')\n",
    "axes[2].set_title(\"Green Channel\")\n",
    "axes[2].axis(\"off\")\n",
    "\n",
    "# Display the Blue channel\n",
    "axes[3].imshow(blue_channel, cmap='Blues')\n",
    "axes[3].set_title(\"Blue Channel\")\n",
    "axes[3].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2KsIGB8shvy"
   },
   "source": [
    "*   The color **red** looks too bright for the eyes. Isn't it?? Lets change the color and see how it appears.\n",
    "    *    Create a new image where everything that is **'red' is changed to 'blue'**.\n",
    "*   Visualize  original image and  created image using matplotlib subplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "111KEZossmpl"
   },
   "outputs": [],
   "source": [
    "# Open  original image again\n",
    "image = Image.open(sample_image_path).convert('RGB')\n",
    "\n",
    "# Convert  image to a numpy array for manipulation\n",
    "image_array = np.array(image)\n",
    "\n",
    "# Swap  red and blue channels\n",
    "# Red is channel 0, Blue is channel 2\n",
    "image_array[:, :, [0, 2]] = image_array[:, :, [2, 0]]\n",
    "\n",
    "# Convert back to an image\n",
    "swapped_image = Image.fromarray(image_array)\n",
    "\n",
    "# Display  modified image\n",
    "plt.imshow(swapped_image)\n",
    "plt.title(\"Everything 'red' is changed to 'blue'\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GVfOvZnCH4pK"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import rgb_to_hsv\n",
    "\n",
    "# Load the uploaded image and convert it to RGB (remove alpha channel if present)\n",
    "uploaded_image_path = \"images\\coat.png\"\n",
    "yellow_coat_image = Image.open(uploaded_image_path).convert('RGB')\n",
    "\n",
    "# Convert the image to a NumPy array\n",
    "coat_rgb_array = np.array(yellow_coat_image, dtype=float) / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "# Convert the RGB image to HSV for color-based masking\n",
    "coat_hsv = rgb_to_hsv(coat_rgb_array)\n",
    "\n",
    "# typical HSV values for yellow\n",
    "yellow_hsv = {\n",
    "    \"hue_min\": 0.14,  # Minimum Hue (normalized)\n",
    "    \"hue_max\": 0.20,  # Maximum Hue (normalized)\n",
    "    \"saturation_min\": 0.4,  # Minimum Saturation (normalized)\n",
    "    \"value_min\": 0.5,  # Minimum Value (normalized)\n",
    "}\n",
    "\n",
    "yellow_mask = (\n",
    "    (coat_hsv[:, :, 0] > yellow_hsv[\"hue_min\"]) & (coat_hsv[:, :, 0] < yellow_hsv[\"hue_max\"]) &\n",
    "    (coat_hsv[:, :, 1] > yellow_hsv[\"saturation_min\"]) &\n",
    "    (coat_hsv[:, :, 2] > yellow_hsv[\"value_min\"])\n",
    ")\n",
    "\n",
    "# Plot the original image and the mask\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Original image\n",
    "axes[0].imshow(yellow_coat_image)\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# Yellow mask\n",
    "axes[1].imshow(yellow_mask, cmap='gray')\n",
    "axes[1].set_title(\"Yellow Coat Mask\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2hsv\n",
    "\n",
    "\n",
    "# Load the model image\n",
    "model_image_path = \"images\\model.png\"\n",
    "coat_image_path = \"images\\coat.png\"\n",
    "coat_image = Image.open(coat_image_path).convert(\"RGBA\")\n",
    "model_image = Image.open(model_image_path).convert(\"RGBA\")\n",
    "\n",
    "\n",
    "# Resize images to the same dimensions\n",
    "model_image = model_image.resize(coat_image.size)\n",
    "\n",
    "# Convert coat image to HSV and create a mask\n",
    "coat_array = np.array(coat_image)\n",
    "coat_hsv = rgb2hsv(coat_array[:, :, :3] / 255.0)\n",
    "yellow_mask = (\n",
    "    (coat_hsv[:, :, 0] > 0.14) & (coat_hsv[:, :, 0] < 0.20) &\n",
    "    (coat_hsv[:, :, 1] > 0.4) & (coat_hsv[:, :, 2] > 0.5)\n",
    ")\n",
    "\n",
    "# Convert mask to an image\n",
    "mask_image = Image.fromarray((yellow_mask * 255).astype(np.uint8))\n",
    "\n",
    "# Composite the images\n",
    "composite_image = Image.composite(coat_image, model_image, mask_image)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(model_image)\n",
    "axes[0].set_title(\"Model\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(coat_image)\n",
    "axes[1].set_title(\"Coat\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "axes[2].imshow(composite_image)\n",
    "axes[2].set_title(\"Model Wearing Coat\")\n",
    "axes[2].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2hsv\n",
    "\n",
    "# Load model and coat images\n",
    "model_image_path = \"images/model.png\"\n",
    "coat_image_path = \"images/coat.png\"\n",
    "texture_image_path = \"images/texture.png\"\n",
    "\n",
    "model_image = Image.open(model_image_path).convert(\"RGBA\")\n",
    "coat_image = Image.open(coat_image_path).convert(\"RGBA\")\n",
    "texture_image = Image.open(texture_image_path).resize(coat_image.size).convert(\"RGBA\")\n",
    "\n",
    "# Resize model to match the coat's dimensions\n",
    "model_image = model_image.resize(coat_image.size)\n",
    "\n",
    "# Convert coat to HSV and create a mask for yellow regions\n",
    "coat_array = np.array(coat_image)\n",
    "coat_hsv = rgb2hsv(coat_array[:, :, :3] / 255.0)\n",
    "yellow_mask = (\n",
    "    (coat_hsv[:, :, 0] > 0.14) & (coat_hsv[:, :, 0] < 0.20) &\n",
    "    (coat_hsv[:, :, 1] > 0.4) & (coat_hsv[:, :, 2] > 0.5)\n",
    ")\n",
    "\n",
    "# Expand the mask to RGBA format\n",
    "yellow_mask_rgba = np.repeat(yellow_mask[:, :, np.newaxis], 4, axis=2)\n",
    "\n",
    "# Convert texture to an array\n",
    "texture_array = np.array(texture_image)\n",
    "\n",
    "# Replace yellow regions with texture\n",
    "textured_coat_array = coat_array.copy()\n",
    "textured_coat_array[yellow_mask_rgba] = texture_array[yellow_mask_rgba]\n",
    "\n",
    "# Convert back to an image\n",
    "textured_coat_image = Image.fromarray(textured_coat_array)\n",
    "\n",
    "# Convert the yellow mask to a single channel for compositing\n",
    "mask_image = Image.fromarray((yellow_mask * 255).astype(np.uint8))\n",
    "\n",
    "# Composite the textured coat onto the model\n",
    "final_image = Image.composite(textured_coat_image, model_image, mask_image)\n",
    "\n",
    "# Display the results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "axes[0].imshow(model_image)\n",
    "axes[0].set_title(\"Model\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(textured_coat_image)\n",
    "axes[1].set_title(\"Textured Coat\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "axes[2].imshow(final_image)\n",
    "axes[2].set_title(\"Model Wearing Textured Coat\")\n",
    "axes[2].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTEmlIhY0w46"
   },
   "source": [
    "# Contrast Enhancement\n",
    "\n",
    "### **Exercise: Histogram Computation**\n",
    "\n",
    "*   Read the **'astronaut' image** from data module.\n",
    "*   Convert the image to grayscale.\n",
    "*   Compute the **histogram of the image.** *Hint: histogram function is available in skimage.exposure package*\n",
    "*   Plot the histogram using matplotlib plot.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pkh-HIjW2SBW"
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from skimage.exposure import histogram\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage.color import rgb2hsv\n",
    "\n",
    "astronaut_image_path = r\"C:\\Users\\dbigman\\OneDrive - SUDOC LLC\\Desktop\\GitHub\\Ironhack_bootcamp\\lab-computer-vision\\.venv\\Lib\\site-packages\\skimage\\data\\astronaut.png\"\n",
    "\n",
    "astronaut_image = Image.open(astronaut_image_path).convert(\"L\")\n",
    "\n",
    "# Convert the PIL Image to a Numpy array\n",
    "image_array = np.array(astronaut_image)\n",
    "\n",
    "# Compute the histogram\n",
    "hist, hist_centers = histogram(image_array)\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(hist_centers, hist, lw=2)\n",
    "plt.title('Grayscale Histogram')\n",
    "plt.xlabel('Pixel intensity')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIeB6eUYs-lR"
   },
   "source": [
    "*   Change the bin count to 8 and compute the histogram of the image and plot the computed histogram using matplotlib plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UXxj9_ZptB0_"
   },
   "outputs": [],
   "source": [
    "from skimage.exposure import histogram\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "astronaut_image_path = r\"C:\\Users\\dbigman\\OneDrive - SUDOC LLC\\Desktop\\GitHub\\Ironhack_bootcamp\\lab-computer-vision\\.venv\\Lib\\site-packages\\skimage\\data\\astronaut.png\"\n",
    "astronaut_image = Image.open(astronaut_image_path).convert(\"L\")\n",
    "\n",
    "image_array = np.array(astronaut_image)\n",
    "\n",
    "# Compute the histogram with 8 bins\n",
    "hist, hist_centers = histogram(image_array, nbins=8)\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(hist_centers, hist, width=(hist_centers[1] - hist_centers[0]), align=\"center\", alpha=0.7, color=\"blue\")\n",
    "plt.title(\"Grayscale Histogram with 8 Bins\")\n",
    "plt.xlabel(\"Pixel Intensity\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyBcGEtEJXP_"
   },
   "source": [
    "\n",
    "\n",
    "*   What happens when you change the bin count? Does your inference change based on the bin count? If yes, then how do you define the correct bin count.\n",
    "*   What happens when the bin count is very low and what happens when it is very high?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tw8L1ZKvKOvo"
   },
   "source": [
    "**Solution**\n",
    "Fewer Bins (8 bins): The histogram becomes coarser, aggregating more intensity levels into each bin. With fewer bins it can seem that the image has less variety in intensity levels than it actually does.\n",
    "\n",
    "More Bins (256 bins): The histogram becomes more detailed, with each bin representing a smaller range of intensity levels. There is more information on the distribution, like as identifying peaks or gaps that represent specific intensity ranges.\n",
    "\n",
    "The correct bin count depends on the application and required detail: fewer bins (e.g., 8–16) are suitable for broad intensity patterns, while more bins (e.g., 64–256) are better for precise tasks like edge detection. High dynamic range images benefit from more bins, whereas low-contrast images may require fewer. For visualization, fewer bins simplify interpretation, while technical tasks like histogram equalization often need higher bin counts. A common starting point is 256 bins for grayscale images, adjusted based on image size and analysis detail.\n",
    "\n",
    "\n",
    "A low bin count aggregates broad intensity ranges, simplifying the histogram but losing detail. Subtle variations and small peaks in intensity are smoothed, potentially causing distinct regions to appear as one and leading to oversimplification in tasks like segmentation. The simplified histogram is easier to interpret and useful for understanding general trends, such as whether an image is mostly dark or bright. \n",
    "\n",
    "When the Bin Count is Very High\n",
    "A high bin count captures fine intensity variations, making the histogram more precise but harder to interpret due to excessive detail. Noise can create clutter, but the granularity is ideal for precision tasks like contrast enhancement or edge detection. This allows for better identification of intensity thresholds and enhances advanced image processing.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ecOWgER2U_n"
   },
   "source": [
    "\n",
    "*   Compute histogram of the color image (without converting it to grayscale).\n",
    "*   Plot the total histogram and also histogram for each channel (show it in a single plot with differnt legends for each histogram).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0R425Nve2Til"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "astronaut_image_path = r\"C:\\Users\\dbigman\\OneDrive - SUDOC LLC\\Desktop\\GitHub\\Ironhack_bootcamp\\lab-computer-vision\\.venv\\Lib\\site-packages\\skimage\\data\\astronaut.png\"\n",
    "\n",
    "image = cv2.imread(astronaut_image_path)\n",
    "\n",
    "# Calculate histograms for each channel\n",
    "colors = ('b', 'g', 'r')  # OpenCV loads images in BGR format\n",
    "histograms = {}\n",
    "\n",
    "# Compute histogram for each channel\n",
    "for i, color in enumerate(colors):\n",
    "    histograms[color] = cv2.calcHist([image], [i], None, [256], [0, 256])\n",
    "\n",
    "# Calculate the total histogram\n",
    "total_histogram = sum(histograms[color] for color in colors)\n",
    "\n",
    "# Plot histograms\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot each channel's histogram\n",
    "for color in colors:\n",
    "    plt.plot(histograms[color], label=f'{color.upper()} Channel')\n",
    "\n",
    "# Plot the total histogram\n",
    "plt.plot(total_histogram, label='Total', color='black', linestyle='--')\n",
    "\n",
    "# Customize plot\n",
    "plt.title('Color Image Histogram')\n",
    "plt.xlabel('Intensity Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vr9af6my4uKv"
   },
   "source": [
    "### **Exercise: Histogram Equalization**\n",
    "\n",
    "*   Read 'aquatermi_lowcontrast.jpg' image from the images folder.\n",
    "*   Compute the histogram of the image.\n",
    "*   Perform histogram equalization of the image to enhance the contrast. *Hint: Use equalize_hist function available in skimage.exposure*\n",
    "*   Also compute histogram of the equalized image.\n",
    "*   Use 2 x 2 subplot to show the original image and the enhanced image along with the corresponding histograms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ROMuC8F6IYf"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "aquatermi_lowcontrast_image_path = r\"images\\aquatermi_lowcontrast.jpg\"\n",
    "# print(os.path.exists(aquatermi_lowcontrast_image_path))\n",
    "\n",
    "image = cv2.imread(aquatermi_lowcontrast_image_path)\n",
    "\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB for visualization\n",
    "\n",
    "# Perform histogram equalization on each channel\n",
    "equalized_image = np.zeros_like(image_rgb)\n",
    "for i in range(3):  # Iterate over R, G, B channels\n",
    "    equalized_image[..., i] = exposure.equalize_hist(image_rgb[..., i]) * 255\n",
    "\n",
    "equalized_image = equalized_image.astype(np.uint8)\n",
    "\n",
    "# Compute histograms\n",
    "def compute_histogram(image, channels=('r', 'g', 'b')):\n",
    "    histograms = {}\n",
    "    for i, color in enumerate(channels):\n",
    "        histograms[color] = cv2.calcHist([image], [i], None, [256], [0, 256])\n",
    "    return histograms\n",
    "\n",
    "original_histograms = compute_histogram(image_rgb)\n",
    "equalized_histograms = compute_histogram(equalized_image)\n",
    "\n",
    "# Plot original and equalized images and their histograms\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Original image\n",
    "axes[0, 0].imshow(image_rgb)\n",
    "axes[0, 0].set_title(\"Original Image\")\n",
    "axes[0, 0].axis(\"off\")\n",
    "\n",
    "# Histogram of original image\n",
    "for color, hist in original_histograms.items():\n",
    "    axes[0, 1].plot(hist, label=f\"{color.upper()} Channel\")\n",
    "axes[0, 1].set_title(\"Original Image Histogram\")\n",
    "axes[0, 1].set_xlabel(\"Intensity Value\")\n",
    "axes[0, 1].set_ylabel(\"Frequency\")\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Equalized image\n",
    "axes[1, 0].imshow(equalized_image)\n",
    "axes[1, 0].set_title(\"Equalized Image\")\n",
    "axes[1, 0].axis(\"off\")\n",
    "\n",
    "# Histogram of equalized image\n",
    "for color, hist in equalized_histograms.items():\n",
    "    axes[1, 1].plot(hist, label=f\"{color.upper()} Channel\")\n",
    "axes[1, 1].set_title(\"Equalized Image Histogram\")\n",
    "axes[1, 1].set_xlabel(\"Intensity Value\")\n",
    "axes[1, 1].set_ylabel(\"Frequency\")\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvDnkRKA8PXe"
   },
   "source": [
    "\n",
    "*   The above function in skimage.exposure uses cdf and interpolation technique to normalize the histogram. How is it different from linear contrast stretch?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOCa3PzJLhl0"
   },
   "source": [
    "**Solution**\n",
    "\n",
    "Histogram Equalization is a non-linear technique that redistributes intensities based on the image's histogram to enhance contrast adaptively. It aims to flatten the histogram\t\n",
    "Linear Contrast Stretch applies a Linear or uniform scaling, depending on min and max values. It aims to produce a scaled version of the input histogram\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "boFCTwGV8kaz"
   },
   "source": [
    "### **Exercise: Linear Contrast Stretch**\n",
    "\n",
    "*   Write a function to compute the linear contrast stretch (Do not use an inbuilt function). \n",
    "*   Provide grayscale image array and bin count as parameters to the function and return the enhanced image array.\n",
    "*   Use a 2 x 2 plot to visualize the original image, histogram, enhanced image and the corresponding histogram.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6mlhI_s8lLv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.exposure import histogram\n",
    "from PIL import Image\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "\n",
    "def linear_contrast_stretch(image, bin_count=256):\n",
    "    \"\"\"\n",
    "    Perform linear contrast stretching on a grayscale image based on a specified bin count.\n",
    "\n",
    "    Parameters:\n",
    "        image (np.ndarray): Input grayscale image as a NumPy array.\n",
    "        bin_count (int): Number of intensity bins (default: 256).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Contrast-stretched image as a NumPy array.\n",
    "    \"\"\"\n",
    "    # Validate the input image\n",
    "    if not isinstance(image, np.ndarray):\n",
    "        raise ValueError(\"Input image must be a NumPy array.\")\n",
    "    if image.ndim != 2:\n",
    "        raise ValueError(\"Input image must be a 2D grayscale image.\")\n",
    "    \n",
    "    # Validate the bin count\n",
    "    if bin_count < 2:\n",
    "        raise ValueError(\"Bin count must be at least 2.\")\n",
    "    \n",
    "    # Convert the image to float for computation\n",
    "    image = np.asarray(image, dtype=np.float32)\n",
    "    \n",
    "    # Get the minimum and maximum pixel values\n",
    "    img_min = np.min(image)\n",
    "    img_max = np.max(image)\n",
    "\n",
    "    # Handle the edge case where all pixel values are the same\n",
    "    if img_max == img_min:\n",
    "        print(\"Warning: All pixel values are the same. Returning a constant image.\")\n",
    "        return np.full_like(image, img_min, dtype=np.uint8)\n",
    "    \n",
    "    # Compute the target intensity range based on the bin count\n",
    "    target_min = 0\n",
    "    target_max = bin_count - 1\n",
    "\n",
    "    # Apply linear contrast stretching\n",
    "    stretched_image = (image - img_min) / (img_max - img_min)  # Normalize to [0, 1]\n",
    "    stretched_image = stretched_image * (target_max - target_min) + target_min  # Scale to target range\n",
    "\n",
    "    # Clip values and convert back to uint8\n",
    "    stretched_image = np.clip(stretched_image, target_min, target_max).astype(np.uint8)\n",
    "    \n",
    "    return stretched_image\n",
    "\n",
    "\n",
    "astronaut_image = data.astronaut()\n",
    "# Convert to grayscale\n",
    "grayscale_image = rgb2gray(astronaut_image)\n",
    "\n",
    "# Convert the PIL Image to a NumPy array\n",
    "image_array = np.array(astronaut_image)\n",
    "\n",
    "# Apply linear contrast stretching\n",
    "bin_count = 256\n",
    "enhanced_image = linear_contrast_stretch(grayscale_image * 255, bin_count=bin_count)\n",
    "\n",
    "# Compute histograms\n",
    "original_hist, original_hist_centers = histogram(image_array)\n",
    "enhanced_hist, enhanced_hist_centers = histogram(enhanced_image)\n",
    "\n",
    "# Create a 2x2 plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Original Image\n",
    "axes[0, 0].imshow(grayscale_image, cmap=\"gray\")\n",
    "axes[0, 0].set_title(\"Original Image\")\n",
    "axes[0, 0].axis(\"off\")\n",
    "\n",
    "# Original Histogram\n",
    "axes[0, 1].plot(original_hist_centers, original_hist, lw=2)\n",
    "axes[0, 1].set_title(\"Original Histogram\")\n",
    "axes[0, 1].set_xlabel(\"Pixel Intensity\")\n",
    "axes[0, 1].set_ylabel(\"Frequency\")\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Enhanced Image\n",
    "axes[1, 0].imshow(enhanced_image, cmap=\"gray\")\n",
    "axes[1, 0].set_title(f\"Enhanced Image (Bin Count: {bin_count})\")\n",
    "axes[1, 0].axis(\"off\")\n",
    "\n",
    "# Enhanced Histogram\n",
    "axes[1, 1].plot(enhanced_hist_centers, enhanced_hist, lw=2, color=\"orange\")\n",
    "axes[1, 1].set_title(\"Enhanced Histogram\")\n",
    "axes[1, 1].set_xlabel(\"Pixel Intensity\")\n",
    "axes[1, 1].set_ylabel(\"Frequency\")\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfuWqX2BWyXm"
   },
   "source": [
    "# Filters\n",
    "\n",
    "### **Exercise: Mean Filter**\n",
    "\n",
    "*   Load the **coins** image from the data module.\n",
    "*   Define a disk structuring element (selem) of radius 20. *Hint: Structuring elements are defined in the skimage.morphology module*\n",
    "*   Use mean filter using the created selem. *Hint: The mean filter is available in skimage.filters.rank module*\n",
    "*   Increase the radius of the selem by 10 and apply the mean filter.\n",
    "*   Reduce the radius of the selem by 10 and apply the mean filter.\n",
    "*   Visualize all the smoothened images along with the original image.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qp7_zxDjL7vS"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "from skimage.morphology import disk\n",
    "from skimage.filters import rank\n",
    "\n",
    "# Load the \"coins\" image\n",
    "coins_image = data.coins()\n",
    "\n",
    "# Define a disk structuring element with a radius of 20\n",
    "selem = disk(radius=20)\n",
    "\n",
    "# Increase the radius by 10\n",
    "increased_selem = disk(radius=30)\n",
    "\n",
    "# Apply the mean filter with the increased structuring element\n",
    "filtered_image = rank.mean(coins_image, footprint=increased_selem)\n",
    "\n",
    "# Plot the results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Original coins image\n",
    "axes[0].imshow(coins_image, cmap=\"gray\")\n",
    "axes[0].set_title(\"Original Coins Image\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# Increased structuring element visualization\n",
    "axes[1].imshow(increased_selem, cmap=\"gray\")\n",
    "axes[1].set_title(\"Structuring Element (Radius = 30)\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "# Filtered image\n",
    "axes[2].imshow(filtered_image, cmap=\"gray\")\n",
    "axes[2].set_title(\"Mean Filtered Image (Radius = 30)\")\n",
    "axes[2].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DIOQCcsvEqG"
   },
   "source": [
    "*   Use different selem (square, rectangle, star, diamond) to view the behaviour of the mean filter (It is not necessary to repeat with different sizes; it is sufficient to show the one with optimal parameter).\n",
    "*   Create a 2 x n subplot to show the selem in the first row and the corresponding smoothened image in the second row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3GbQXmYvvXUO"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "from skimage.morphology import disk, square, rectangle, diamond, star\n",
    "from skimage.filters import rank\n",
    "\n",
    "# Load the \"coins\" image\n",
    "coins_image = data.coins()\n",
    "\n",
    "# Define different structuring elements\n",
    "selems = {\n",
    "    \"Square\": square(20),\n",
    "    \"Rectangle\": rectangle(20, 10),\n",
    "    \"Star\": star(20),\n",
    "    \"Diamond\": diamond(20),\n",
    "}\n",
    "\n",
    "# Apply mean filter with different structuring elements\n",
    "filtered_images = {name: rank.mean(coins_image, footprint=selem) for name, selem in selems.items()}\n",
    "\n",
    "# Plot the results\n",
    "fig, axes = plt.subplots(1, len(selems) + 1, figsize=(20, 8))\n",
    "\n",
    "# Original image\n",
    "axes[0].imshow(coins_image, cmap=\"gray\")\n",
    "axes[0].set_title(\"Original Coins Image\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# Filtered images\n",
    "for ax, (name, filtered_image) in zip(axes[1:], filtered_images.items()):\n",
    "    ax.imshow(filtered_image, cmap=\"gray\")\n",
    "    ax.set_title(f\"Mean Filter with {name}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jV7OHQwKZ9GU"
   },
   "source": [
    "*   How does changing the radius of disk affect the smoothing functionality?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QG91LBzwMBUR"
   },
   "source": [
    "**Solution**\n",
    "\n",
    "The radius of the disk structuring element determines the size of the \"neighborhood\" used for smoothing. A smaller radius has more details and edges, providing localized smoothing with less noise reduction. A larger radius smooths over larger regions, reducing noise significantly but potentially losing detail. The choice of radius depends on the application, balancing detail preservation with noise reduction, and larger radii may be more complicated computationally. \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPJFLYMkMBqs"
   },
   "source": [
    "\n",
    "*   What is the observed behaviour with difference in the structuring element?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcJkpvnjMFY5"
   },
   "source": [
    "**Solution**\n",
    "\n",
    "Structuring elements influence smoothing by changing the shape and directionality of the neighborhood. Symmetric elements like disks and squares provide uniform smoothing, while asymmetric elements like rectangles and stars introduce directional effects, emphasizing specific orientations. The structuring element depends on the image and the desired outcome, like preserving circular features or enhancing textures.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5hySxTKM4AB"
   },
   "source": [
    "\n",
    "\n",
    "*   What is the difference between mean filter and gaussian filter?\n",
    "*   Where do you use mean filters and where do you use gaussian filters?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0foSx_GNDB5"
   },
   "source": [
    "**Solution**\n",
    "\n",
    "The mean filter replaces each pixel’s value with the average value of its neighbors, resulting in smoothing by reducing sharp transitions. It is computationally simple and effectively reduces random noise but may blur edges. \n",
    "\n",
    "The Gaussian filter uses a weighted average of the neighboring pixels, giving more importance to those closer to the center based on a Gaussian function. It smooths images while preserving edges better than a mean filter, thanks to its localized weighting. \n",
    "\n",
    "\n",
    "\n",
    "Mean filters are commonly used in preprocessing for low-complexity noise reduction in images.\n",
    "Gaussian filters are preferred for tasks requiring noise reduction with minimal edge distortion, like preprocessing for computer vision.\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPs+7OmQKl06bCVLggAj4BU",
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
